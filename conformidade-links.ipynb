{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "import time\n",
    "\n",
    "# Lê a planiha Conformidade Legal \n",
    "#(https://docs.google.com/spreadsheets/d/1_teMusgzqisvbbL3TOONcjJSBibTTae5AIKp-oeceQg/edit?gid=0#gid=0)\n",
    "\n",
    "# Em resumo, esse trecho do código, lê todas as abas da planilha do google sheets Conformidade Legal\n",
    "# e monta um dataframe único com todos os dados.\n",
    "# Esse processo é interessante de ser realizado via Phyton devido a muitas vezes quando da utilização \n",
    "# da solução nativa do Power BI (conector do google sheets) termos experimentados erros com relação \n",
    "# à quantidade de requisições (Erro: Too many requests).\n",
    "\n",
    "# Caminho para o arquivo de credenciais\n",
    "SERVICE_ACCOUNT_FILE = \"E:\\\\conformidade\\\\iconic-apricot-248419-55a189fad524.json\"\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "SHEET_ID = \"1_teMusgzqisvbbL3TOONcjJSBibTTae5AIKp-oeceQg\"\n",
    "\n",
    "# Autenticação com a API do Google Sheets\n",
    "credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "service = build('sheets', 'v4', credentials=credentials)\n",
    "sheet = service.spreadsheets()\n",
    "\n",
    "# Obter todas as abas da planilha\n",
    "spreadsheet = sheet.get(spreadsheetId=SHEET_ID).execute()\n",
    "sheet_names = [sheet['properties']['title'] for sheet in spreadsheet['sheets']]\n",
    "\n",
    "# DataFrame vazio para armazenar todos os links\n",
    "dados = pd.DataFrame()\n",
    "\n",
    "# Iterar por cada aba e extrair os dados, ignorando a aba \"Dados\"\n",
    "for sheet_name in sheet_names:\n",
    "    if sheet_name == \"Dados\":\n",
    "        continue  # Ignora a aba \"Dados\"\n",
    "    \n",
    "    RANGE = f\"{sheet_name}!A1:R1000\"  # Ajuste o intervalo conforme necessário\n",
    "    result = sheet.values().get(spreadsheetId=SHEET_ID, range=RANGE, valueRenderOption='FORMATTED_VALUE').execute()\n",
    "    values = result.get('values', [])\n",
    "\n",
    "    if values:\n",
    "        # Verificar se o número de colunas no cabeçalho é igual ao número de colunas nos dados\n",
    "        num_columns = len(values[0])\n",
    "        for row in values[1:]:\n",
    "            while len(row) < num_columns:\n",
    "                row.append(\"\")  # Preencher colunas vazias com string vazia\n",
    "            while len(row) > num_columns:\n",
    "                row.pop()  # Remover colunas extras\n",
    "\n",
    "        # Criar DataFrame a partir da aba atual\n",
    "        dados_aux = pd.DataFrame(values[1:], columns=values[0])  # Primeira linha como cabeçalho\n",
    "        dados=pd.concat([dados,dados_aux],ignore_index=True)\n",
    "        # Verificar os nomes das colunas\n",
    "        #print(f\"Colunas da aba '{sheet_name}': {df.columns.tolist()}\")\n",
    "\n",
    "dados[\"IAD\"]= dados[\"ESTADO DE CUMPRIMENTO\"].apply(\n",
    "                lambda x:\"\" if x in [\"Em Análise\",\"Em análise\",\"Não se aplica\"] else x)\n",
    "dados['NORMA - ORIGEM']=dados['NORMA']+\" - \"+dados['ORIGEM']                \n",
    "        \n",
    "# Salvar os links em um arquivo CSV\n",
    "dados.to_csv('E:\\\\conformidade\\\\Dados.csv', index=False)\n",
    "print(\"Arquivo 'dados.csv' foi gerado com sucesso.\")\n",
    "\n",
    "# A partir desse ponto inicia-se a geração da tabela de links. A partir dela é que vamos identificar\n",
    "# quais são as normas que já têm o questionário respondido a fim de que se possa incluir as informações\n",
    "# no BI Conformidade.\n",
    "# O resultado é incluído na variável \"links_filtrados\" e salvo em um arquivo .csv de mesmo nome.\n",
    "\n",
    "links=dados[[\"NORMA\",\"ORIGEM\",\"LINK PARA PLANILHA\",\"ÁREA RESPONSÁVEL\"]]\n",
    "# Remover espaços extras das células da coluna 'LINK PARA FORMULÁRIO'\n",
    "links['LINK PARA PLANILHA'] = links['LINK PARA PLANILHA'].str.strip()\n",
    "links['NORMA - ORIGEM']=links['NORMA']+\" - \"+links['ORIGEM']\n",
    "\n",
    "# Filtrar o DataFrame para manter apenas as linhas com link informado (não vazio ou nulo)\n",
    "links_filtrados = links[links['LINK PARA PLANILHA'].str.startswith('https://', na=False)]\n",
    "\n",
    "# Opcionalmente, verificar se o filtro foi aplicado corretamente:\n",
    "print(f\"Total de linhas antes do filtro: {len(links)}\")\n",
    "print(f\"Total de linhas após o filtro: {len(links_filtrados)}\")\n",
    "\n",
    "# Salvar os links filtrados em um novo arquivo CSV\n",
    "links_filtrados.to_csv('E:\\\\conformidade\\\\links_filtrados.csv', index=False)\n",
    "print(\"Arquivo 'links_filtrados.csv' foi gerado com sucesso.\")\n",
    "#print(links_filtrados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesse trecho, geramos uma base única com todas as informações provenientes de todas as planilhas\n",
    "# dos questionários respondidos. O resultado é salvo na variável \"base_transposta\" e em um arquivo\n",
    "# .csv denomeminado \"base.csv\". \n",
    "\n",
    "\n",
    "# Ler arquivo com links\n",
    "links_filtrados = pd.read_csv(r'E:\\conformidade\\links_filtrados.csv')\n",
    "\n",
    "# Extrair IDs das planilhas\n",
    "links_filtrados['LINK PLANILHA'] = links_filtrados['LINK PARA PLANILHA'].str.extract(r'/d/([^/]+)/')\n",
    "SHEET_IDS_ITENS = links_filtrados['LINK PLANILHA'].dropna().tolist()\n",
    "\n",
    "# Inicializar lista para armazenar os DataFrames temporários\n",
    "dataframes = []\n",
    "base_transposta=pd.DataFrame()\n",
    "# Processar cada planilha\n",
    "for index, sheet_id_item in enumerate(SHEET_IDS_ITENS):\n",
    "    try: \n",
    "        # Obter valores da planilha\n",
    "        RANGE_ITEM = \"A1:ZZZ2\"\n",
    "        resultado = sheet.values().get(spreadsheetId=sheet_id_item, range=RANGE_ITEM, valueRenderOption='FORMATTED_VALUE').execute()\n",
    "        valores = resultado.get('values', [])\n",
    "        \n",
    "        if valores:\n",
    "            # Ajustar inconsistências no número de colunas\n",
    "            num_columns = len(valores[0])\n",
    "            valores = [row + [\"\"] * (num_columns - len(row)) for row in valores]\n",
    "            \n",
    "            # Criar DataFrame com os dados da planilha\n",
    "            base_aux = pd.DataFrame(valores[1:], columns=valores[0])\n",
    "            \n",
    "            # Adicionar a linha 'norma' ao final do DataFrame temporário\n",
    "            norma_row = [links_filtrados.iloc[index]['NORMA - ORIGEM']] * len(valores[0])  # Preencher a linha com a norma\n",
    "            origem_row = [links_filtrados.iloc[index]['ORIGEM']] * len(valores[0])  # Preencher a linha com a origem\n",
    "            area_row= [links_filtrados.iloc[index]['ÁREA RESPONSÁVEL']] * len(valores[0])  # Preencher a linha com a área responsável\n",
    "            base_aux.loc[len(base_aux)] = norma_row  # Adiciona a linha ao final do DataFrame\n",
    "            base_aux.loc[len(base_aux)] = origem_row  # Adiciona a linha ao final do DataFrame\n",
    "            base_aux.loc[len(base_aux)] = area_row  # Adiciona a linha ao final do DataFrame\n",
    "            \n",
    "            # Adicionar o DataFrame à lista\n",
    "            #dataframes.append(base_aux)\n",
    "            #base = pd.concat(dataframes, ignore_index=True)\n",
    "            base_transposta_aux = base_aux.transpose()\n",
    "            base_transposta=pd.concat([base_transposta,base_transposta_aux],ignore_index=False)\n",
    "        time.sleep(5)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar a planilha {sheet_id_item}: {e}\")\n",
    "\n",
    "base_transposta = base_transposta.drop(['Carimbo de data/hora','Comentário / Evidências',\n",
    "                                       'Comentário/Evidência'], axis=0)\n",
    "# Criar uma máscara para identificar as linhas que contêm as expressões\n",
    "masc=~base_transposta.index.str.contains(r\"evidência do cumprimento\",case=False,na=False)\n",
    "base_transposta=base_transposta[masc]\n",
    "\n",
    "# Salvar o DataFrame transposto como CSV\n",
    "output_path = r'E:\\conformidade\\base.csv'\n",
    "base_transposta.to_csv(output_path, index=True)\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fim de comparar a eficiência de montar as tabelas dimensão diretamente no power bi e fora dele, \n",
    "# vou gerar as tabelas dimensão em arquivos .csv com base na variável \"dados\" que está no primeiro \n",
    "# chunck desse código.\n",
    "\n",
    "origem = pd.DataFrame(dados['ORIGEM'].unique())\n",
    "tema = pd.DataFrame(dados['TEMA'].unique())\n",
    "tipo_norma = pd.DataFrame([\"Resolução\"])\n",
    "area= pd.DataFrame(dados['ÁREA RESPONSÁVEL'].unique())\n",
    "estado_analise= pd.DataFrame(['Analisado','Em Análise','Não se Aplica'])\n",
    "ano= pd.DataFrame(dados['DATA DE REGISTRO'].str.extract(r'(\\d{4}$)',expand=False).unique())\n",
    "situacao= pd.DataFrame(dados['SITUAÇÃO'].unique())\n",
    "norma=pd.DataFrame(dados['NORMA - ORIGEM'].unique())\n",
    "\n",
    "origem.to_csv(r'E:\\conformidade\\tab_dimensao\\dOrigem.csv')\n",
    "tema.to_csv(r'E:\\conformidade\\tab_dimensao\\dTema.csv')\n",
    "tipo_norma.to_csv(r'E:\\conformidade\\tab_dimensao\\dTipo_de_Norma.csv')\n",
    "area.to_csv(r'E:\\conformidade\\tab_dimensao\\dArea.csv')\n",
    "estado_analise.to_csv(r'E:\\conformidade\\tab_dimensao\\dEstado_de_Analise.csv')\n",
    "ano.to_csv(r'E:\\conformidade\\tab_dimensao\\dAno.csv')\n",
    "situacao.to_csv(r'E:\\conformidade\\tab_dimensao\\dSituacao.csv')\n",
    "norma.to_csv(r'E:\\conformidade\\tab_dimensao\\dNorma.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
