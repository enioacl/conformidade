{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abce8597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enioacl\\AppData\\Local\\Temp/ipykernel_16124/2160530752.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  links['LINK PARA PLANILHA'] = links['LINK PARA PLANILHA'].str.strip()\n",
      "C:\\Users\\enioacl\\AppData\\Local\\Temp/ipykernel_16124/2160530752.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  links['NORMA - ORIGEM']=links['NORMA']+\" - \"+links['ORIGEM']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "import time\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Lê a planiha Conformidade Legal \n",
    "#(https://docs.google.com/spreadsheets/d/1_teMusgzqisvbbL3TOONcjJSBibTTae5AIKp-oeceQg/edit?gid=0#gid=0)\n",
    "\n",
    "# Em resumo, esse trecho do código, lê todas as abas da planilha do google sheets Conformidade Legal\n",
    "# e monta um dataframe único com todos os dados.\n",
    "# Esse processo é interessante de ser realizado via Phyton devido a muitas vezes quando da utilização \n",
    "# da solução nativa do Power BI (conector do google sheets) termos experimentados erros com relação \n",
    "# à quantidade de requisições (Erro: Too many requests).\n",
    "\n",
    "# Caminho para o arquivo de credenciais\n",
    "SERVICE_ACCOUNT_FILE = \"C:\\\\Arquivos\\\\Documents\\\\GOOGLESHEETS_TOKEN.json\"\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "SHEET_ID = \"1_teMusgzqisvbbL3TOONcjJSBibTTae5AIKp-oeceQg\"\n",
    "\n",
    "# Autenticação com a API do Google Sheets\n",
    "credentials = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "service = build('sheets', 'v4', credentials=credentials)\n",
    "sheet = service.spreadsheets()\n",
    "\n",
    "# Obter todas as abas da planilha\n",
    "spreadsheet = sheet.get(spreadsheetId=SHEET_ID).execute()\n",
    "sheet_names = [sheet['properties']['title'] for sheet in spreadsheet['sheets']]\n",
    "\n",
    "# DataFrame vazio para armazenar todos os links\n",
    "dados = pd.DataFrame()\n",
    "\n",
    "# Iterar por cada aba e extrair os dados, ignorando a aba \"Dados\"\n",
    "for sheet_name in sheet_names:\n",
    "    if sheet_name == \"Dados\":\n",
    "        continue  # Ignora a aba \"Dados\"\n",
    "    \n",
    "    RANGE = f\"{sheet_name}!A1:R1000\"  # Ajuste o intervalo conforme necessário\n",
    "    result = sheet.values().get(spreadsheetId=SHEET_ID, range=RANGE, valueRenderOption='FORMATTED_VALUE').execute()\n",
    "    values = result.get('values', [])\n",
    "\n",
    "    if values:\n",
    "        # Verificar se o número de colunas no cabeçalho é igual ao número de colunas nos dados\n",
    "        num_columns = len(values[0])\n",
    "        for row in values[1:]:\n",
    "            while len(row) < num_columns:\n",
    "                row.append(\"\")  # Preencher colunas vazias com string vazia\n",
    "            while len(row) > num_columns:\n",
    "                row.pop()  # Remover colunas extras\n",
    "\n",
    "        # Criar DataFrame a partir da aba atual\n",
    "        dados_aux = pd.DataFrame(values[1:], columns=values[0])  # Primeira linha como cabeçalho\n",
    "        dados=pd.concat([dados,dados_aux],ignore_index=True)\n",
    "        # Verificar os nomes das colunas\n",
    "        #print(f\"Colunas da aba '{sheet_name}': {df.columns.tolist()}\")\n",
    "\n",
    "dados[\"IAD\"]= dados[\"ESTADO DE CUMPRIMENTO\"].apply(\n",
    "                lambda x:\"\" if x in [\"Em Análise\",\"Em análise\",\"Não se aplica\"] else x)\n",
    "dados['NORMA - ORIGEM']=dados['NORMA']+\" - \"+dados['ORIGEM']                \n",
    "        \n",
    "\n",
    "# A partir desse ponto inicia-se a geração da tabela de links. A partir dela é que vamos identificar\n",
    "# quais são as normas que já têm o questionário respondido a fim de que se possa incluir as informações\n",
    "# no BI Conformidade.\n",
    "\n",
    "links=dados[[\"NORMA\",\"ORIGEM\",\"LINK PARA PLANILHA\",\"ÁREA RESPONSÁVEL\",\"ESTADO DE CUMPRIMENTO\"]]\n",
    "# Remover espaços extras das células da coluna 'LINK PARA FORMULÁRIO'\n",
    "links['LINK PARA PLANILHA'] = links['LINK PARA PLANILHA'].str.strip()\n",
    "links['NORMA - ORIGEM']=links['NORMA']+\" - \"+links['ORIGEM']\n",
    "\n",
    "# Filtrar o DataFrame para manter apenas as linhas com link informado (não vazio ou nulo)\n",
    "links_filtrados = links[links['LINK PARA PLANILHA'].str.startswith('https://', na=False)]\n",
    "links_filtrados = links_filtrados[(links_filtrados['ESTADO DE CUMPRIMENTO'] != \"Em análise\") & \n",
    "                                  (links_filtrados['ESTADO DE CUMPRIMENTO'] != \"Não se aplica\")]\n",
    "\n",
    "\n",
    "# Nesse trecho, geramos uma base única com todas as informações provenientes de todas as planilhas\n",
    "# dos questionários respondidos. O resultado é salvo na variável \"base_transposta\".\n",
    "\n",
    "# Extrair IDs das planilhas\n",
    "links_filtrados['LINK PLANILHA'] = links_filtrados['LINK PARA PLANILHA'].str.extract(r'/d/([^/]+)/')\n",
    "SHEET_IDS_ITENS = links_filtrados['LINK PLANILHA'].dropna().tolist()\n",
    "\n",
    "# Inicializar lista para armazenar os DataFrames temporários\n",
    "dataframes = []\n",
    "base_transposta=pd.DataFrame()\n",
    "# Processar cada planilha\n",
    "for index, sheet_id_item in enumerate(SHEET_IDS_ITENS):\n",
    "    try: \n",
    "        # Obter valores da planilha\n",
    "        RANGE_ITEM = \"A1:ZZZ2\"\n",
    "        resultado = sheet.values().get(spreadsheetId=sheet_id_item, range=RANGE_ITEM, valueRenderOption='FORMATTED_VALUE').execute()\n",
    "        valores = resultado.get('values', [])\n",
    "        \n",
    "        if valores:\n",
    "            # Ajustar inconsistências no número de colunas\n",
    "            num_columns = len(valores[0])\n",
    "            valores = [row + [\"\"] * (num_columns - len(row)) for row in valores]\n",
    "            \n",
    "            # Criar DataFrame com os dados da planilha\n",
    "            base_aux = pd.DataFrame(valores[1:], columns=valores[0])\n",
    "            \n",
    "            # Adicionar a linha 'norma' ao final do DataFrame temporário\n",
    "            norma_row = [links_filtrados.iloc[index]['NORMA - ORIGEM']] * len(valores[0])  # Preencher a linha com a norma\n",
    "            origem_row = [links_filtrados.iloc[index]['ORIGEM']] * len(valores[0])  # Preencher a linha com a origem\n",
    "            area_row= [links_filtrados.iloc[index]['ÁREA RESPONSÁVEL']] * len(valores[0])  # Preencher a linha com a área responsável\n",
    "            base_aux.loc[len(base_aux)] = norma_row  # Adiciona a linha ao final do DataFrame\n",
    "            base_aux.loc[len(base_aux)] = origem_row  # Adiciona a linha ao final do DataFrame\n",
    "            base_aux.loc[len(base_aux)] = area_row  # Adiciona a linha ao final do DataFrame\n",
    "            \n",
    "            # Adicionar o DataFrame à lista\n",
    "            base_transposta_aux = base_aux.transpose()\n",
    "            base_transposta=pd.concat([base_transposta,base_transposta_aux],ignore_index=False)\n",
    "        time.sleep(5)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar a planilha {sheet_id_item}: {e}\")\n",
    "\n",
    "base_transposta = base_transposta.drop(['Carimbo de data/hora','Comentário / Evidências',\n",
    "                                       'Comentário/Evidência'], axis=0)\n",
    "# Criar uma máscara para identificar as linhas que contêm as expressões\n",
    "masc=~base_transposta.index.str.contains(r\"evidência do cumprimento\",case=False,na=False)\n",
    "base_transposta=base_transposta[masc]\n",
    "\n",
    "# Criando as tabelas dimensão\n",
    "\n",
    "origem = pd.DataFrame(dados['ORIGEM'].unique())\n",
    "tema = pd.DataFrame(dados['TEMA'].unique())\n",
    "tipo_norma = pd.DataFrame([\"Resolução\"])\n",
    "area= pd.DataFrame(dados['ÁREA RESPONSÁVEL'].unique())\n",
    "estado_analise= pd.DataFrame(['Analisado','Em Análise','Não se Aplica'])\n",
    "ano= pd.DataFrame(dados['DATA DE REGISTRO'].str.extract(r'(\\d{4}$)',expand=False).unique())\n",
    "situacao= pd.DataFrame(dados['SITUAÇÃO'].unique())\n",
    "norma=pd.DataFrame(dados['NORMA - ORIGEM'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15eaebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token carregado com sucesso!\n",
      "Buscando informações do arquivo: Dados.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando commit/push para Dados.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit/push realizado com sucesso para Dados.csv!\n",
      "Buscando informações do arquivo: base.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando commit/push para base.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commit/push realizado com sucesso para base.csv!\n",
      "Buscando informações do arquivo: tab_dimensao/dAno.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dAno.csv é idêntico ao atual. Nenhuma atualização será feita.\n",
      "Buscando informações do arquivo: tab_dimensao/dArea.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dArea.csv é idêntico ao atual. Nenhuma atualização será feita.\n",
      "Buscando informações do arquivo: tab_dimensao/dEstado_de_Analise.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dEstado_de_Analise.csv é idêntico ao atual. Nenhuma atualização será feita.\n",
      "Buscando informações do arquivo: tab_dimensao/dNorma.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dNorma.csv é idêntico ao atual. Nenhuma atualização será feita.\n",
      "Buscando informações do arquivo: tab_dimensao/dOrigem.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dOrigem.csv é idêntico ao atual. Nenhuma atualização será feita.\n",
      "Buscando informações do arquivo: tab_dimensao/dSituacao.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dSituacao.csv é idêntico ao atual. Nenhuma atualização será feita.\n",
      "Buscando informações do arquivo: tab_dimensao/dTema.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dTema.csv é idêntico ao atual. Nenhuma atualização será feita.\n",
      "Buscando informações do arquivo: tab_dimensao/dTipo_de_Norma.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conteúdo de tab_dimensao/dTipo_de_Norma.csv é idêntico ao atual. Nenhuma atualização será feita.\n"
     ]
    }
   ],
   "source": [
    "# Fazendo upload para o GitHub dos arquivos resultantes da execução do código acima\n",
    "# Configurações gerais\n",
    "repo_owner = \"enioacl\"  # Nome do usuário ou organização\n",
    "repo_name = \"conformidade\"  # Nome do repositório\n",
    "branch = \"main\"\n",
    "base_api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/\"\n",
    "token = os.getenv('GITHUB_TOKEN')\n",
    "if token is None:\n",
    "    print(\"Token do GitHub não encontrado!\")\n",
    "else:\n",
    "    print(\"Token carregado com sucesso!\")\n",
    "\n",
    "# Arquivos e conteúdos a serem atualizados\n",
    "\n",
    "arquivos = [\n",
    "    {\n",
    "        \"file_path\": \"Dados.csv\",  # Caminho do arquivo no repositório\n",
    "        \"content\": dados.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando Dados.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"base.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": base_transposta.to_csv(index=True),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando base de itens.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dAno.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": ano.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dAno\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dArea.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": area.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dArea\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dEstado_de_Analise.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": estado_analise.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dEstado_de_analise\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dNorma.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": norma.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dNorma\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dOrigem.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": origem.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dOrigem\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dSituacao.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": situacao.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dSituacao\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dTema.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": tema.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dTema\"\n",
    "    },\n",
    "    {\n",
    "        \"file_path\": \"tab_dimensao/dTipo_de_Norma.csv\",  # Caminho do segundo arquivo no repositório\n",
    "        \"content\": tipo_norma.to_csv(index=False),  # Convertendo DataFrame para CSV\n",
    "        \"commit_message\": \"Atualizando a tabela dimensão dTipo_de_Norma\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Função para atualizar um arquivo\n",
    "def atualizar_arquivo(file_path, content, commit_message):\n",
    "    api_url = f\"{base_api_url}{file_path}\"\n",
    "    encoded_content = base64.b64encode(content.encode()).decode()\n",
    "\n",
    "    # Obter SHA do arquivo existente\n",
    "    print(f\"Buscando informações do arquivo: {file_path}\")\n",
    "    response = requests.get(api_url, headers={\"Authorization\": f\"token {token}\"},verify=False)\n",
    "    if response.status_code == 200:\n",
    "        file_info = response.json()\n",
    "        sha = file_info.get('sha')\n",
    "        existing_content = base64.b64decode(file_info.get('content', '')).decode()\n",
    "        if content == existing_content:\n",
    "            print(f\"O conteúdo de {file_path} é idêntico ao atual. Nenhuma atualização será feita.\")\n",
    "            return\n",
    "    elif response.status_code == 404:\n",
    "        print(f\"Arquivo {file_path} não encontrado no repositório. Ele será criado.\")\n",
    "        sha = None\n",
    "    else:\n",
    "        print(f\"Erro ao buscar o arquivo {file_path}: {response.status_code} - {response.json()}\")\n",
    "        return\n",
    "\n",
    "    # Dados do commit\n",
    "    data = {\n",
    "        \"message\": commit_message,\n",
    "        \"content\": encoded_content,\n",
    "        \"branch\": branch\n",
    "    }\n",
    "    if sha:\n",
    "        data[\"sha\"] = sha\n",
    "\n",
    "    # Fazer a requisição para criar/atualizar o arquivo\n",
    "    print(f\"Realizando commit/push para {file_path}...\")\n",
    "    commit_response = requests.put(api_url, json=data, headers={\"Authorization\": f\"token {token}\"},verify=False)\n",
    "    if commit_response.status_code in [200, 201]:\n",
    "        print(f\"Commit/push realizado com sucesso para {file_path}!\")\n",
    "    else:\n",
    "        print(f\"Erro ao realizar o commit/push para {file_path}: {commit_response.status_code}\")\n",
    "        print(commit_response.json())\n",
    "\n",
    "# Atualizar todos os arquivos na lista\n",
    "for arquivo in arquivos:\n",
    "    atualizar_arquivo(arquivo[\"file_path\"], arquivo[\"content\"], arquivo[\"commit_message\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
